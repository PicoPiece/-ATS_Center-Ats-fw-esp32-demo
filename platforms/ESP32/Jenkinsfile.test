pipeline {
    agent none

    parameters {
        string(
            name: 'BUILD_JOB_NAME',
            defaultValue: 'platforms/ESP32/ats-fw-esp32-demo',
            description: 'Name of the build job that produced the firmware (with folder path)'
        )
        string(
            name: 'BUILD_NUMBER',
            defaultValue: '',
            description: 'Build number of the firmware to test'
        )
        string(
            name: 'ATS_NODE_LABEL',
            defaultValue: 'raspi-ats-01',
            description: 'Label for ATS node pool (e.g., ats-node, ats-pi-01)'
        )
        choice(
            name: 'IMAGE_SOURCE',
            choices: ['registry', 'build'],
            description: 'Unused: pipeline always builds ats-node-test from latest ats-ats-node'
        )
        string(
            name: 'ATS_NODE_TEST_IMAGE',
            defaultValue: 'ghcr.io/picopiece/ats-node-test:latest',
            description: 'Docker image name for ATS node test container (registry or local)'
        )
        string(
            name: 'GHCR_CREDENTIALS_ID',
            defaultValue: '',
            description: 'Jenkins Credentials ID for GitHub Container Registry (GHCR) login (e.g., ghcr-creds). Leave empty if image is public.'
        )
        string(
            name: 'TEST_REPO_URL',
            defaultValue: 'https://github.com/PicoPiece/ats-test-esp32-demo.git',
            description: 'Git URL of the test framework repository'
        )
        string(
            name: 'TEST_REPO_BRANCH',
            defaultValue: 'main',
            description: 'Branch of the test framework repository to use'
        )
    }

    environment {
        WORKSPACE_DIR = "workspace"
        RESULTS_DIR = "results"
        TEST_REPO_DIR = "ats-test-esp32-demo"
    }

    stages {
        stage('Prepare Workspace') {
            agent { label "${params.ATS_NODE_LABEL}" }
            steps {
                script {
                    if (!params.BUILD_NUMBER || params.BUILD_NUMBER == '') {
                        error("BUILD_NUMBER parameter is required")
                    }
                    
                    // Create workspace directory
                    sh """
                        mkdir -p ${WORKSPACE_DIR}
                        cd ${WORKSPACE_DIR}
                    """
                    
                    // Copy firmware artifacts from build job
                    echo "üì• Copying firmware artifacts from ${params.BUILD_JOB_NAME} #${params.BUILD_NUMBER}"
                    
                    // Copy artifacts in two steps to ensure both are copied
                    copyArtifacts(
                        projectName: params.BUILD_JOB_NAME,
                        selector: [
                            $class: 'SpecificBuildSelector',
                            buildNumber: params.BUILD_NUMBER.toString()
                        ],
                        filter: "*.bin",
                        target: WORKSPACE_DIR,
                        flatten: true
                    )
                    
                    copyArtifacts(
                        projectName: params.BUILD_JOB_NAME,
                        selector: [
                            $class: 'SpecificBuildSelector',
                            buildNumber: params.BUILD_NUMBER.toString()
                        ],
                        filter: "ats-manifest.yaml",
                        target: WORKSPACE_DIR,
                        flatten: true
                    )
                    
                    // Verify artifacts were copied
                    sh """
                        echo "üì¶ Verifying copied artifacts..."
                        echo "   Workspace directory: ${WORKSPACE_DIR}"
                        echo "   Current directory: \$(pwd)"
                        echo ""
                        echo "   All files in workspace:"
                        ls -lah ${WORKSPACE_DIR}/ || true
                        echo ""
                        echo "   Firmware binaries:"
                        ls -lh ${WORKSPACE_DIR}/*.bin 2>/dev/null || echo "   ‚ö†Ô∏è  No .bin files found"
                        echo ""
                        echo "   Manifest file:"
                        if [ -f ${WORKSPACE_DIR}/ats-manifest.yaml ]; then
                            echo "   ‚úÖ ats-manifest.yaml found"
                            ls -lh ${WORKSPACE_DIR}/ats-manifest.yaml
                        else
                            echo "   ‚ùå ats-manifest.yaml NOT found"
                            echo "   This will cause the test stage to fail!"
                        fi
                        echo ""
                    """
                    
                    // Checkout test framework
                    echo "üì¶ Checking out test framework: ${params.TEST_REPO_URL}"
                    dir(WORKSPACE_DIR) {
                        checkout([
                            $class: 'GitSCM',
                            branches: [[name: "*/${params.TEST_REPO_BRANCH}"]],
                            doGenerateSubmoduleConfigurations: false,
                            extensions: [[
                                $class: 'RelativeTargetDirectory',
                                relativeTargetDir: TEST_REPO_DIR
                            ]],
                            submoduleCfg: [],
                            userRemoteConfigs: [[
                                url: params.TEST_REPO_URL,
                                credentialsId: ''
                            ]]
                        ])
                    }
                    
                    // Verify workspace structure and fail if manifest is missing
                    sh """
                        echo "‚úÖ Final workspace verification:"
                        echo "   Workspace: ${WORKSPACE_DIR}"
                        ls -lah ${WORKSPACE_DIR}/ || true
                        echo ""
                        echo "üìã Manifest verification:"
                        if [ -f ${WORKSPACE_DIR}/ats-manifest.yaml ]; then
                            echo "‚úÖ Manifest found:"
                            cat ${WORKSPACE_DIR}/ats-manifest.yaml
                            echo ""
                            echo "‚úÖ Workspace preparation completed successfully"
                        else
                            echo "‚ùå ERROR: Manifest NOT found in ${WORKSPACE_DIR}/"
                            echo ""
                            echo "   Troubleshooting:"
                            echo "   1. Check if build job '${params.BUILD_JOB_NAME}' #${params.BUILD_NUMBER} exists"
                            echo "   2. Verify build job archived 'ats-manifest.yaml'"
                            echo "   3. Check Jenkins console for copyArtifacts errors"
                            echo "   4. Verify BUILD_NUMBER parameter is correct"
                            echo ""
                            echo "   Current workspace contents:"
                            ls -la ${WORKSPACE_DIR}/ || true
                            echo ""
                            exit 1
                        fi
                    """
                }
            }
        }

        stage('Build ATS Node Test Image from Latest') {
            agent { label "${params.ATS_NODE_LABEL}" }
            steps {
                dir(WORKSPACE_DIR) {
                    sh """
                        #!/bin/bash
                        set -eu
                        echo "üê≥ Building ATS node test image from latest ats-ats-node (always ensure up-to-date)"
                        WORKSPACE_ABS=\$(pwd)
                        echo "   Workspace: \$WORKSPACE_ABS"
                        echo ""
                        
                        if [ ! -d "\${WORKSPACE_ABS}/ats-ats-node" ]; then
                            echo "üì¶ Cloning ats-ats-node..."
                            git clone https://github.com/PicoPiece/ats-ats-node.git ats-ats-node || { echo "‚ùå Failed to clone ats-ats-node"; exit 1; }
                        else
                            echo "üì¶ Pulling latest ats-ats-node..."
                            cd \${WORKSPACE_ABS}/ats-ats-node
                            git fetch origin && git pull origin main || { echo "‚ö†Ô∏è  git pull failed, using existing code"; true; }
                            cd "\$WORKSPACE_ABS"
                        fi
                        
                        if [ -d "\${WORKSPACE_ABS}/ats-ats-node/docker/ats-node-test" ] && [ -f "\${WORKSPACE_ABS}/ats-ats-node/docker/ats-node-test/Dockerfile" ]; then
                            echo "üî® Building image: ${params.ATS_NODE_TEST_IMAGE}"
                            cd \${WORKSPACE_ABS}/ats-ats-node/docker/ats-node-test
                            if docker buildx version > /dev/null 2>&1; then
                                export DOCKER_BUILDKIT=1
                            fi
                            docker build --pull -t ${params.ATS_NODE_TEST_IMAGE} .
                            echo "‚úÖ Image built from latest ats-ats-node: ${params.ATS_NODE_TEST_IMAGE}"
                        else
                            echo "‚ùå ERROR: Dockerfile not found at \${WORKSPACE_ABS}/ats-ats-node/docker/ats-node-test/"
                            ls -la "\${WORKSPACE_ABS}/ats-ats-node/" || true
                            exit 1
                        fi
                    """
                }
            }
        }

        stage('Prepare ATS Node Test Container') {
            agent { label "${params.ATS_NODE_LABEL}" }
            steps {
                script {
                    // Image already built from latest in previous stage; just verify it exists
                    echo "üìã Verifying ATS node test image (built from latest ats-ats-node)"
                    echo "   Image: ${params.ATS_NODE_TEST_IMAGE}"
                    def img = sh(
                        script: "docker images -q ${params.ATS_NODE_TEST_IMAGE}",
                        returnStdout: true
                    ).trim()
                    if (!img) {
                        error("ATS node test image not found: ${params.ATS_NODE_TEST_IMAGE}. Build stage may have failed.")
                    }
                    echo "‚úÖ Image found, ready for test stage"
                }
            }
        }

        stage('Run ATS Tests') {
            agent { label "${params.ATS_NODE_LABEL}" }
            steps {
                dir(WORKSPACE_DIR) {
                    sh """
                        echo "üöÄ [ATS] Running test execution container"
                        echo "üìã Image: ${params.ATS_NODE_TEST_IMAGE}"
                        echo "üìÅ Workspace: \$(pwd)"
                        
                        # Verify workspace contents before running container
                        echo "üì¶ Workspace contents:"
                        ls -lah \$(pwd)/
                        echo ""
                        
                        # Verify manifest exists
                        if [ ! -f ats-manifest.yaml ]; then
                            echo "‚ùå ERROR: ats-manifest.yaml not found in workspace!"
                            echo "   Expected path: \$(pwd)/ats-manifest.yaml"
                            echo "   Current directory: \$(pwd)"
                            echo "   Files in workspace:"
                            ls -lah \$(pwd)/ || true
                            echo ""
                            echo "   This usually means:"
                            echo "   1. Build job did not archive ats-manifest.yaml"
                            echo "   2. copyArtifacts failed in Prepare Workspace stage"
                            echo "   3. Wrong BUILD_NUMBER parameter"
                            exit 1
                        fi
                        
                        echo "‚úÖ Manifest found: \$(pwd)/ats-manifest.yaml"
                        echo "üìã Manifest content:"
                        cat ats-manifest.yaml
                        echo ""
                        
                        # Verify firmware binary exists
                        FW_BIN=\$(ls *.bin 2>/dev/null | head -1)
                        if [ -z "\$FW_BIN" ]; then
                            echo "‚ö†Ô∏è  Warning: No .bin firmware file found in workspace"
                        else
                            echo "‚úÖ Firmware binary found: \$FW_BIN"
                        fi
                        echo ""
                        
                        # Create results directory
                        mkdir -p ${RESULTS_DIR}
                        
                        # Ensure manifest and directory are readable by container
                        chmod 644 ats-manifest.yaml || true
                        chmod 755 . || true  # Ensure directory is traversable
                        chown \$(id -u):\$(id -g) ats-manifest.yaml 2>/dev/null || true
                        echo "üîç File permissions on host:"
                        ls -lah ats-manifest.yaml
                        echo "üîç Directory permissions:"
                        ls -ld .
                        echo ""
                        
                        # CRITICAL: Jenkins agent runs in a container, and we're running Docker inside that container
                        # This is a "Docker-in-Docker" scenario where we need to mount from the HOST filesystem
                        # 
                        # Agent container setup (from start-agent.sh):
                        #   -v /home/jenkins:/home/jenkins/agent (host -> container)
                        #   -v /var/run/docker.sock:/var/run/docker.sock
                        #
                        # So if we're at /home/jenkins/workspace/... in agent container,
                        # the HOST path is also /home/jenkins/workspace/... (same path on host)
                        #
                        # However, Docker inside container needs to mount from HOST, not container filesystem
                        # Solution: Use the path as-is since agent container mounts host /home/jenkins directly
                        
                        WORKSPACE_ABS=\$(pwd)
                        echo "üîç Current directory (in agent container): \${WORKSPACE_ABS}"
                        
                        # Verify we can see files from agent container perspective
                        echo "üîç Files visible from agent container:"
                        ls -lah \${WORKSPACE_ABS}/ | head -10
                        echo ""
                        
                        # Since agent container mounts /home/jenkins from host, the path should work
                        # But we need to ensure Docker can access it. Try to find the actual host mount point
                        # Check if we're in a container by looking at /.dockerenv or /proc/1/cgroup
                        if [ -f /.dockerenv ] || grep -qa docker /proc/1/cgroup 2>/dev/null; then
                            echo "üîç Running inside container (Jenkins agent)"
                            echo "   Agent container should have mounted host /home/jenkins"
                            echo "   Using path as-is for Docker mount: \${WORKSPACE_ABS}"
                        else
                            echo "üîç Running directly on host"
                            echo "   Using path as-is: \${WORKSPACE_ABS}"
                        fi
                        
                        # CRITICAL FIX for Docker-in-Docker: Use Docker volumes instead of bind mounts
                        # When Docker runs inside a container, bind mounts from container filesystem don't work
                        # Solution: Create a Docker volume and copy files into it
                        
                        echo "üîç Detected Docker-in-Docker scenario - using Docker volume instead of bind mount"
                        echo ""
                        
                        # Create a named Docker volume
                        WORKSPACE_VOLUME="jenkins-workspace-\$(date +%s)"
                        echo "üì¶ Creating Docker volume: \${WORKSPACE_VOLUME}"
                        docker volume create \${WORKSPACE_VOLUME} || {
                            echo "‚ùå Failed to create Docker volume"
                            exit 1
                        }
                        echo "‚úÖ Docker volume created"
                        echo ""
                        
                        # Copy files into the volume using tar pipe (works in Docker-in-Docker)
                        # This avoids bind mount which doesn't work in nested containers
                        echo "üìã Copying workspace files into Docker volume using tar pipe..."
                        echo "   Source: \${WORKSPACE_ABS}"
                        echo "   Volume: \${WORKSPACE_VOLUME}"
                        echo ""
                        
                        # Method: tar from workspace -> pipe -> tar into volume container
                        # This works because we're copying from container filesystem, not mounting
                        cd \${WORKSPACE_ABS}
                        tar -czf - . | docker run --rm -i \\
                            -v \${WORKSPACE_VOLUME}:/workspace \\
                            alpine:latest sh -c "
                                echo 'Extracting files into volume...'
                                cd /workspace
                                tar -xzf - || {
                                    echo '‚ùå Failed to extract files'
                                    exit 1
                                }
                                echo '‚úÖ Files extracted successfully'
                                echo ''
                                echo 'Verifying files in volume:'
                                ls -lah /workspace/ | head -10
                                echo ''
                                echo 'Verifying manifest file:'
                                test -f /workspace/ats-manifest.yaml && echo '‚úÖ Manifest file exists' || echo '‚ùå Manifest file missing'
                                echo ''
                                echo 'File count:'
                                find /workspace -type f | wc -l
                            " || {
                            echo "‚ùå Failed to copy files into volume"
                            docker volume rm \${WORKSPACE_VOLUME} 2>/dev/null || true
                            exit 1
                        }
                        echo ""
                        
                        # Verify volume has files
                        echo "üîç Verifying volume contents..."
                        VOLUME_TEST=\$(docker run --rm -v \${WORKSPACE_VOLUME}:/workspace alpine:latest sh -c "test -f /workspace/ats-manifest.yaml && echo 'FILE_EXISTS' || echo 'FILE_MISSING'" 2>&1)
                        
                        if echo "\$VOLUME_TEST" | grep -q "FILE_EXISTS"; then
                            echo "‚úÖ Volume test PASSED - files are accessible in volume"
                            echo "   File content preview:"
                            docker run --rm -v \${WORKSPACE_VOLUME}:/workspace alpine:latest head -5 /workspace/ats-manifest.yaml 2>&1 || true
                            echo ""
                            echo "‚úÖ Using Docker volume: \${WORKSPACE_VOLUME}"
                            USE_VOLUME=true
                        else
                            echo "‚ùå Volume test FAILED"
                            echo "   Test output: \$VOLUME_TEST"
                            docker volume rm \${WORKSPACE_VOLUME} 2>/dev/null || true
                            exit 1
                        fi
                        echo ""
                        
                        # Run test container with workspace mount
                        # Use Docker volume if we're in Docker-in-Docker scenario, otherwise use bind mount
                        echo "üöÄ Running ATS test container..."
                        
                        # Detect serial port on host/agent for ESP32 flash (pass into container so flash can use it)
                        SERIAL_PORT=""
                        for p in /dev/ttyUSB0 /dev/ttyUSB1 /dev/ttyACM0 /dev/ttyACM1; do
                            if [ -e "\$p" ]; then
                                SERIAL_PORT="\$p"
                                break
                            fi
                        done
                        if [ -n "\${SERIAL_PORT}" ]; then
                            echo "   Serial port on agent: \${SERIAL_PORT} (will pass to container as SERIAL_PORT)"
                            SERIAL_ENV="-e SERIAL_PORT=\${SERIAL_PORT}"
                        else
                            echo "   ‚ö†Ô∏è  No serial port found on agent (no /dev/ttyUSB* or /dev/ttyACM*). ESP32 flash will fail unless USB is passed through."
                            SERIAL_ENV=""
                        fi
                        
                        EXIT_CODE=0
                        if [ "\${USE_VOLUME}" = "true" ]; then
                            echo "   Using Docker volume: \${WORKSPACE_VOLUME} -> /workspace"
                            docker run --rm --privileged \\
                                -v \${WORKSPACE_VOLUME}:/workspace \\
                                -v /dev:/dev \\
                                -v /sys/class/gpio:/sys/class/gpio:ro \\
                                -v /dev/gpiomem:/dev/gpiomem \\
                                -v /var/lib/ats-metrics:/var/lib/ats-metrics \\
                                -e MANIFEST_PATH=/workspace/ats-manifest.yaml \\
                                -e RESULTS_DIR=/workspace/${RESULTS_DIR} \\
                                -e HOST_METRICS_FILE=/var/lib/ats-metrics/metrics.json \\
                                \${SERIAL_ENV} \\
                                ${params.ATS_NODE_TEST_IMAGE} || EXIT_CODE=\$?
                            
                            # Copy results back from volume to workspace
                            echo ""
                            echo "üì¶ Copying results back from Docker volume..."
                            
                            # Ensure results directory exists before copying
                            mkdir -p ${RESULTS_DIR}
                            chmod 755 ${RESULTS_DIR} || true
                            rm -f ${RESULTS_DIR}/* 2>/dev/null || true
                            
                            # Create tar archive (redirect echo to stderr, only tar to stdout)
                            echo "   Creating tar archive from volume..."
                            docker run --rm \\
                                -v \${WORKSPACE_VOLUME}:/source:ro \\
                                alpine:latest sh -c "
                                    if [ -d /source/${RESULTS_DIR} ]; then
                                        cd /source/${RESULTS_DIR}
                                        tar -czf - . 2>&1
                                    else
                                        echo '‚ö†Ô∏è  Results directory not found' >&2
                                        exit 1
                                    fi
                                " > ${RESULTS_DIR}/results.tar.gz 2>${RESULTS_DIR}/tar_errors.log || {
                                echo "‚ùå Failed to create tar from volume"
                                echo "   Error log:"
                                cat ${RESULTS_DIR}/tar_errors.log 2>/dev/null || true
                                exit 1
                            }
                            
                            # Verify tar file was created and has content
                            TAR_SIZE=\$(stat -c%s ${RESULTS_DIR}/results.tar.gz 2>/dev/null || echo "0")
                            if [ "\${TAR_SIZE}" -eq 0 ]; then
                                echo "‚ùå Tar file is empty"
                                cat ${RESULTS_DIR}/tar_errors.log 2>/dev/null || true
                                exit 1
                            fi
                            rm -f ${RESULTS_DIR}/tar_errors.log 2>/dev/null || true
                            
                            # Extract tar archive to results directory
                            tar -xzf ${RESULTS_DIR}/results.tar.gz -C ${RESULTS_DIR}/ 2>&1 || {
                                echo "‚ùå Failed to extract tar archive"
                                exit 1
                            }
                            rm -f ${RESULTS_DIR}/results.tar.gz 2>/dev/null || true
                            
                            # Verify files were copied
                            FILE_COUNT=\$(find ${RESULTS_DIR} -type f 2>/dev/null | wc -l)
                            if [ "\${FILE_COUNT}" -eq 0 ]; then
                                echo "‚ùå No files found after copy"
                                exit 1
                            fi
                            echo "‚úÖ Results copied: \${FILE_COUNT} files"
                            
                            # Fix ownership and permissions
                            chown -R \$(id -u):\$(id -g) ${RESULTS_DIR}/ 2>/dev/null || true
                            find ${RESULTS_DIR} -type f -exec chmod 644 {} \\; 2>/dev/null || true
                            find ${RESULTS_DIR} -type d -exec chmod 755 {} \\; 2>/dev/null || true
                            
                            # Cleanup volume
                            echo "üßπ Cleaning up Docker volume..."
                            docker volume rm \${WORKSPACE_VOLUME} 2>/dev/null || echo "‚ö†Ô∏è  Failed to remove volume (may be in use)"
                        else
                            echo "   Using bind mount: \${WORKSPACE_ABS} -> /workspace"
                        docker run --rm --privileged \\
                                -v "\${WORKSPACE_ABS}:/workspace" \\
                            -v /dev:/dev \\
                            -v /sys/class/gpio:/sys/class/gpio:ro \\
                            -v /dev/gpiomem:/dev/gpiomem \\
                            -v /var/lib/ats-metrics:/var/lib/ats-metrics \\
                            -e MANIFEST_PATH=/workspace/ats-manifest.yaml \\
                            -e RESULTS_DIR=/workspace/${RESULTS_DIR} \\
                            -e HOST_METRICS_FILE=/var/lib/ats-metrics/metrics.json \\
                            \${SERIAL_ENV} \\
                            ${params.ATS_NODE_TEST_IMAGE} || EXIT_CODE=\$?
                        fi
                        
                        if [ \$EXIT_CODE -eq 0 ]; then
                            echo "‚úÖ Test execution completed successfully"
                        elif [ \$EXIT_CODE -eq 1 ]; then
                            echo "‚ö†Ô∏è  Test execution completed with test failures (exit code 1) ‚Äî will mark build UNSTABLE"
                        else
                            echo "‚ùå Test execution failed with exit code: \$EXIT_CODE"
                        fi
                        
                        echo "üìä Results:"
                        ls -la ${RESULTS_DIR}/ || echo "   No results found"
                        
                        # Persist exit code so pipeline can set UNSTABLE (1) vs FAILURE (2+); stage must not fail so Archive runs
                        echo \$EXIT_CODE > ${RESULTS_DIR}/.exitcode
                        exit 0
                    """
                    script {
                        if (!fileExists("${RESULTS_DIR}/.exitcode")) {
                            echo "‚ö†Ô∏è  .exitcode not found, assuming run error"
                            currentBuild.result = 'FAILURE'
                            error("Test stage did not produce .exitcode")
                            return
                        }
                        def exitCode = readFile("${RESULTS_DIR}/.exitcode").trim().toInteger()
                        if (exitCode == 1) {
                            currentBuild.result = 'UNSTABLE'
                            echo "‚ö†Ô∏è  Build set to UNSTABLE (some tests failed; results archived)"
                        } else if (exitCode != 0) {
                            currentBuild.result = 'FAILURE'
                            error("Test container exited with code ${exitCode}")
                        }
                    }
                }
            }
        }

        stage('Archive Results') {
            agent { label "${params.ATS_NODE_LABEL}" }
            steps {
                dir(WORKSPACE_DIR) {
                    script {
                        // Verify results exist before archiving using shell commands (sandbox-safe)
                        def resultsExist = sh(
                            script: "test -d ${RESULTS_DIR} && echo 'EXISTS' || echo 'NOT_EXISTS'",
                            returnStdout: true
                        ).trim()
                        
                        if (resultsExist == 'EXISTS') {
                            echo "üì¶ Archiving results from ${RESULTS_DIR}"
                            
                            // List all files with sizes
                            def fileList = sh(
                                script: "find ${RESULTS_DIR} -type f -exec ls -lh {} \\; | awk '{print \$9, \"(\", \$5, \")\"}'",
                                returnStdout: true
                            ).trim()
                            
                            if (fileList) {
                                echo "   Files to archive:"
                                fileList.split('\n').each { line ->
                                    echo "   - ${line}"
                                }
                            } else {
                                echo "   ‚ö†Ô∏è  Results directory is empty"
                            }
                            
                            // Archive all result files
                            archiveArtifacts artifacts: "${RESULTS_DIR}/**", allowEmptyArchive: false
                            
                            // Publish JUnit test results
                            def junitFiles = sh(
                                script: "find ${RESULTS_DIR} -name '*.xml' -type f",
                                returnStdout: true
                            ).trim()
                            
                            if (junitFiles) {
                                echo "üìä Publishing JUnit test results:"
                                junitFiles.split('\n').each { file ->
                                    echo "   - ${file}"
                                }
                                junit testResults: "${RESULTS_DIR}/**/*.xml", allowEmptyResults: true
                            } else {
                                echo "   ‚ö†Ô∏è  No JUnit XML files found"
                            }
                        } else {
                            echo "   ‚ö†Ô∏è  Results directory does not exist: ${RESULTS_DIR}"
                            error("Results directory not found - cannot archive artifacts")
                        }
                    }
                }
            }
        }

        stage('Update Grafana Metrics') {
            agent { label "${params.ATS_NODE_LABEL}" }
            steps {
                dir(WORKSPACE_DIR) {
                    sh """
                        echo "üìä Updating Prometheus metrics for Grafana..."
                        
                        METRICS_SRC="${RESULTS_DIR}/metrics.json"
                        METRICS_DST="/var/lib/ats-metrics/metrics.json"
                        
                        if [ -f "\${METRICS_SRC}" ]; then
                            # Directory should already exist with open permissions (setup by ats-ci-infra)
                            mkdir -p /var/lib/ats-metrics 2>/dev/null || true
                            
                            cp "\${METRICS_SRC}" "\${METRICS_DST}"
                            echo "‚úÖ Metrics copied to \${METRICS_DST}"
                            echo "   Contents:"
                            cat "\${METRICS_DST}"
                        else
                            echo "‚ö†Ô∏è  metrics.json not found in \${METRICS_SRC}"
                            echo "   Grafana metrics will not be updated this run"
                        fi
                    """
                }
            }
        }
    }

    post {
        success {
            echo "‚úÖ Firmware tested successfully on ATS node"
        }
        failure {
            echo "‚ùå Firmware test failed"
        }
        always {
            node("${params.ATS_NODE_LABEL}") {
                dir(WORKSPACE_DIR) {
                    archiveArtifacts artifacts: "${RESULTS_DIR}/**", allowEmptyArchive: true
                }
            }
        }
    }
}
